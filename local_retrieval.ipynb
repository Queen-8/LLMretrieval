{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c26b4ee",
   "metadata": {},
   "source": [
    "加载文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents: 4\n",
      "First document text: 1\n",
      "CSRF\n",
      "1. 原理\n",
      "2. 与XSS区别\n",
      "3. 常见场景\n",
      "4. 常见漏洞点\n",
      "5. 漏洞危害\n",
      "6. CSRF Poc 构造\n",
      "7. 漏洞审计\n",
      "8. 漏洞修复\n",
      "9. Webgoat\n",
      "跨站请求伪造（Cro\n",
      "First document text: 1\n",
      "XXE 漏洞\n",
      "1. xml基本介绍\n",
      "1.1. 什么是xml\n",
      "1.2. xml 内容示例\n",
      "1.2.1. DTD 约束\n",
      "1.2.2. 内部实体 Internal Entity\n",
      "1.2.3. 外部实体 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import fitz  # PyMuPDF, 用于PDF文本提取\n",
    "from dotenv import load_dotenv  # 用于加载.env环境变量\n",
    "from langchain.vectorstores import Chroma  # 向量数据库\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings  # 向量化\n",
    "from langchain.text_splitter import CharacterTextSplitter  # 文本分片\n",
    "from langchain.llms import OpenAI  # OpenAI LLM调用\n",
    "\n",
    "# 加载本地.env文件中的环境变量（如API KEY）\n",
    "load_dotenv()\n",
    "\n",
    "# 读取OpenAI密钥\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 设置使用的模型（OpenRouter上的GPT-4o-mini）\n",
    "OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "# 配置日志，方便调试\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_pdf_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Load all the PDF files in the specified folder, \n",
    "    returning the full text content of each file (string list).\n",
    "    \"\"\"\n",
    "    all_documents = []\n",
    "    # Iterate over all pdf files\n",
    "    for filename in glob.glob(f\"Local_knowledge_base/*.pdf\"):\n",
    "        document_text = \"\"\n",
    "        # Open the PDF and iterate over each page, accumulating the text\n",
    "        with fitz.open(filename) as doc:\n",
    "            for page_num in range(doc.page_count):\n",
    "                page = doc.load_page(page_num)\n",
    "                document_text += page.get_text(\"text\")\n",
    "        all_documents.append(document_text)\n",
    "    return all_documents\n",
    "\n",
    "\n",
    "# 调用函数并打印\n",
    "all_documents = load_pdf_from_folder(\"Local_knowledge_base\")  # 传入PDF所在文件夹路径\n",
    "print(\"Loaded documents:\", len(all_documents))\n",
    "print(\"First document text:\", all_documents[0][:100])  # 打印第一个文档的前100个字符\n",
    "print(\"Second document text:\", all_documents[1][:100])  # 打印第二个文档的前100个字符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294c07a",
   "metadata": {},
   "source": [
    "分片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f13ca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1976, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1961, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1465, which is longer than the specified 1000\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 6692, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 15\n",
      "First chunk text: 1\n",
      "CSRF\n",
      "1. 原理\n",
      "2. 与XSS区别\n",
      "3. 常见场景\n",
      "4. 常见漏洞点\n",
      "5. 漏洞危害\n",
      "6. CSRF Poc 构造\n",
      "7. 漏洞审计\n",
      "8. 漏洞修复\n",
      "9. Webgoat\n",
      "跨站请求伪造（Cro\n",
      "Second chunk text: 一次完整的 CSRF 攻击需要具备以下两个条件：\n",
      "用户已经登录某站点，并且在浏览器中存储了登录后的 Cookie 信息。\n",
      "在不注销某站点的情况下，去访问攻击者构造的站点。\n",
      "例：\n",
      "网站管理员添加用户的 \n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, overlap=100):\n",
    "    \"\"\"\n",
    "    对每个文档做分片，chunk_size控制单片长度，overlap保证上下文连贯\n",
    "    输入: 字符串list，输出: 分片list\n",
    "    \"\"\"\n",
    "    # 将字符串列表转换为Document对象列表\n",
    "    doc_objects = [Document(page_content=doc) for doc in documents]\n",
    "    \n",
    "    # 创建text_splitter对象\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "    \n",
    "    # 分片并返回结果\n",
    "    return text_splitter.split_documents(doc_objects)\n",
    "\n",
    "# 使用示例\n",
    "split_docs = split_documents(all_documents, chunk_size=1000, overlap=100)\n",
    "print(\"Number of document chunks:\", len(split_docs))\n",
    "# 使用示例\n",
    "print(\"First chunk text:\", split_docs[0].page_content[:100])  # 打印第一个分片的前100个字符\n",
    "print(\"Second chunk text:\", split_docs[1].page_content[:100])  # 打印第二个分片的前100个字符\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbb309",
   "metadata": {},
   "source": [
    "索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "319da18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: shibing624/text2vec-base-chinese\n",
      "/Users/queen/Documents/VSCode/llm_retrieval/.venv/lib/python3.13/site-packages/transformers/models/bert/tokenization_bert.py:120: RuntimeWarning: coroutine 'build_index' was never awaited\n",
      "  self.ids_to_tokens = collections.OrderedDict([(ids, tok) for tok, ids in self.vocab.items()])\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built with 57 document chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def build_index(documents):\n",
    "    \"\"\"\n",
    "    Convert the sharded documents into vectors and index them\n",
    "    \"\"\"\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"shibing624/text2vec-base-chinese\")\n",
    "    \n",
    "    # 将文档列表转换为Document对象（确保doc是字符串类型）\n",
    "    doc_objects = [Document(page_content=str(doc)) for doc in documents]\n",
    "    \n",
    "    # 使用Chroma创建向量索引\n",
    "    index = Chroma.from_documents(doc_objects, embeddings)\n",
    "    \n",
    "    return index\n",
    "\n",
    "# 使用示例：假设split_docs包含分片后的文档列表\n",
    "index = build_index(split_docs)\n",
    "\n",
    "# 打印索引信息（获取索引中文档数量）\n",
    "print(\"Index built with\", index._collection.count(), \"document chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30172746",
   "metadata": {},
   "source": [
    "召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "464e4896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 content: page_content='2024 年世界职业院校技能大赛\n",
      "制度汇编\n",
      "世界职业院校技能大赛执行委员会（筹）\n",
      "2024 年9 月\n",
      "目\n",
      "录\n",
      "世界职业院校技能大赛管理规定与办法\n",
      "组织机构与职能分工....\n",
      "Document 2 content: page_content='1\n",
      "SSRF漏洞\n",
      "1. SSRF漏洞\n",
      "1.1. 原理\n",
      "1.2. 漏洞危害\n",
      "1.3. 容易出现漏洞的地方\n",
      "2. 漏洞审计点\n",
      "2.1. URLConnection\n",
      "2.2. H\n",
      "Document 3 content: page_content='1\n",
      "SSRF漏洞\n",
      "1. SSRF漏洞\n",
      "1.1. 原理\n",
      "1.2. 漏洞危害\n",
      "1.3. 容易出现漏洞的地方\n",
      "2. 漏洞审计点\n",
      "2.1. URLConnection\n",
      "2.2. H\n",
      "Document 4 content: page_content='1\n",
      "SSRF漏洞\n",
      "1. SSRF漏洞\n",
      "1.1. 原理\n",
      "1.2. 漏洞危害\n",
      "1.3. 容易出现漏洞的地方\n",
      "2. 漏洞审计点\n",
      "2.1. URLConnection\n",
      "2.2. H\n",
      "Document 5 content: page_content='1\n",
      "SSRF漏洞\n",
      "1. SSRF漏洞\n",
      "1.1. 原理\n",
      "1.2. 漏洞危害\n",
      "1.3. 容易出现漏洞的地方\n",
      "2. 漏洞审计点\n",
      "2.1. URLConnection\n",
      "2.2. H\n"
     ]
    }
   ],
   "source": [
    "def recall_documents(query, index, k=5):\n",
    "    \"\"\"\n",
    "    A similarity retrieval is performed and the k most similar documents to the query are returned\n",
    "    \"\"\"\n",
    "    return index.similarity_search(query, k=k)\n",
    "\n",
    "# 使用示例\n",
    "query = \"2024年世界职业院校分为哪些赛道?\"\n",
    "retrieved_docs = recall_documents(query, index, k=5)\n",
    "\n",
    "# 打印检索到的文档内容\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {i+1} content:\", doc.page_content[:100])  # 打印每个文档的前100个字符\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ec6ba",
   "metadata": {},
   "source": [
    "重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c11b1080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded: sk-or...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# 获取项目根目录（.env 所在目录）\n",
    "root_dir = Path().resolve().parent\n",
    "\n",
    "# 加载项目根目录下的 .env 文件中的 OPENROUTER_API_KEY\n",
    "load_dotenv(dotenv_path=root_dir / \".env\")\n",
    "\n",
    "# 测试输出\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found in .env!\")\n",
    "print(\"✅ API key loaded:\", api_key[:5] + \"...\")    # 👈 看看是不是 None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "064bf401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked Document 1 content: page_content='2024 年世界职业院校技能大赛\n",
      "制度汇编\n",
      "世界职业院校技能大赛执行委员会（筹）\n",
      "2024 年9 月\n",
      "目\n",
      "录\n",
      "世界职业院校技能大赛管理规定与办法\n",
      "组织机构与职能分工....\n",
      "Reranked Document 2 content: page_content='1\n",
      "SSRF漏洞\n",
      "1. SSRF漏洞\n",
      "1.1. 原理\n",
      "1.2. 漏洞危害\n",
      "1.3. 容易出现漏洞的地方\n",
      "2. 漏洞审计点\n",
      "2.1. URLConnection\n",
      "2.2. H\n",
      "Reranked Document 3 content: page_content='1\n",
      "SSRF漏洞\n",
      "1. SSRF漏洞\n",
      "1.1. 原理\n",
      "1.2. 漏洞危害\n",
      "1.3. 容易出现漏洞的地方\n",
      "2. 漏洞审计点\n",
      "2.1. URLConnection\n",
      "2.2. H\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# 加载项目根目录下的 .env 文件中的 OPENROUTER_API_KEY\n",
    "root_dir = Path().resolve().parent\n",
    "load_dotenv(dotenv_path=root_dir / \".env\")\n",
    "# 从 .env 读取 OPENROUTER_API_KEY，并设置成 OpenAI 兼容变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# 获取 OPENROUTER_API_KEY 环境变量\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "def rerank_documents(query, retrieved_docs):\n",
    "    \"\"\"\n",
    "    Reorder retrieved documents using LLM or models\n",
    "    \"\"\"\n",
    "    \n",
    "    # 使用ChatOpenAI进行重排\n",
    "    llm = ChatOpenAI(openai_api_key=api_key, model=\"openai/gpt-4o-mini\")\n",
    "    scores = []\n",
    "    \n",
    "    # 为每个文档生成相关性分数\n",
    "    for doc in retrieved_docs:\n",
    "        prompt = f\"Query: {query}\\nDocument: {doc.page_content}\\n\"\n",
    "        \n",
    "        # 构建适合ChatOpenAI的消息格式\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant helping to rank documents based on relevance.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        # 获取相关性分数，确保传递正确的消息列表格式\n",
    "        response = llm.invoke(messages)  # 确保使用 invoke 来调用\n",
    "        \n",
    "        # 提取模型生成的内容（直接访问 content 属性）\n",
    "        score = response.content  # 获取生成的文本\n",
    "        \n",
    "        scores.append((score, doc))\n",
    "    \n",
    "    # 按照分数对文档进行排序\n",
    "    sorted_docs = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # 返回排序后的文档\n",
    "    return [doc[1] for doc in sorted_docs]\n",
    "\n",
    "# 使用示例：假设你已经调用了 recall_documents 获取了 retrieved_docs\n",
    "query = \"2024年世界职业院校分为哪些赛道?\"\n",
    "retrieved_docs = recall_documents(query, index, k=3)\n",
    "\n",
    "# 重排检索到的文档\n",
    "reranked_docs = rerank_documents(query, retrieved_docs)\n",
    "\n",
    "# 打印重排后的文档内容\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "    print(f\"Reranked Document {i+1} content:\", doc.page_content[:100])  # 打印每个文档的前100个字符\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a13553",
   "metadata": {},
   "source": [
    "生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a824d19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answer for query: 2024年世界职业院校分为哪些赛道?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated answer: 2024年世界职业院校技能大赛共设置42个赛道。这些赛道涉及不同的专业领域，具体的赛道信息可能会在相关的赛事通知或指南中详细列出。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# 加载项目根目录下的 .env 文件中的 OPENROUTER_API_KEY\n",
    "root_dir = Path().resolve().parent\n",
    "load_dotenv(dotenv_path=root_dir / \".env\")\n",
    "\n",
    "# 从 .env 读取 OPENROUTER_API_KEY，并设置成 OpenAI 兼容变量\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# 获取 OPENROUTER_API_KEY 环境变量\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "def generate_answer(query, top_docs):\n",
    "    \"\"\"\n",
    "    基于查询和重排后的文档生成最终答案\n",
    "    \"\"\"\n",
    "    # 将文档内容拼接为一个字符串（确保传递给模型的是一个长文本）\n",
    "    documents_content = \"\\n\".join([doc.page_content for doc in top_docs])\n",
    "    \n",
    "    # 格式化prompt，确保传递给模型的是一个字符串\n",
    "    prompt = f\"Answer the following question based on the retrieved documents:\\n{documents_content}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    \n",
    "    # 使用ChatOpenAI进行生成\n",
    "    llm = ChatOpenAI(openai_api_key=api_key, model=\"openai/gpt-4o-mini\")\n",
    "    \n",
    "    try:\n",
    "        # 调用模型生成答案\n",
    "        response = llm.invoke([{\"role\": \"system\", \"content\": \"You are an assistant helping to answer questions based on documents.\"},\n",
    "                               {\"role\": \"user\", \"content\": prompt}])\n",
    "        \n",
    "        # 获取生成的答案（通常是从 response.content 中提取）\n",
    "        answer = response.content.strip()  # 提取生成的文本，去除多余的空格\n",
    "        \n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 使用示例：假设你已经调用了 recall_documents 获取了 retrieved_docs 和 reranked_docs\n",
    "query = \"2024年世界职业院校分为哪些赛道?\"\n",
    "print(\"Generating answer for query:\", query)\n",
    "\n",
    "# 调用生成答案的函数\n",
    "answer = generate_answer(query, reranked_docs)\n",
    "\n",
    "# 打印生成的答案\n",
    "if answer:\n",
    "    print(\"Generated answer:\", answer)\n",
    "else:\n",
    "    print(\"Failed to generate an answer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e07cfe",
   "metadata": {},
   "source": [
    "集成 FastMCP 创建 MCP 服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22a15c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. FastMCP will be managed automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/queen/Documents/VSCode/llm_retrieval/.venv/lib/python3.13/site-packages/fastmcp/server/server.py:213: DeprecationWarning: Providing `log_level` when creating a server is deprecated. Provide it when calling `run` or as a global setting instead.\n",
      "  self._handle_deprecated_settings(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "# 加载项目根目录下的 .env 文件中的 OPENROUTER_API_KEY\n",
    "root_dir = Path().resolve().parent\n",
    "load_dotenv(dotenv_path=root_dir / \".env\")\n",
    "\n",
    "# 获取 OPENROUTER_API_KEY 环境变量\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# 定义知识库路径\n",
    "knowledge_base_folder = \"/Users/queen/Documents/VSCode/llm_retrieval/Local_knowledge_base\"\n",
    "\n",
    "# 创建 FastMCP 实例\n",
    "mcp = FastMCP(\"localRetrieval\", log_level=\"ERROR\")\n",
    "\n",
    "@mcp.tool(name=\"doc_init\", description=\"A server for handling document retrieval and answer generation\")\n",
    "async def doc_init(self, knowledge_base_folder):\n",
    "    \"\"\"\n",
    "    异步文档初始化，构建文档索引\n",
    "    \"\"\"\n",
    "    self.index = build_index(knowledge_base_folder)  # 构建文档索引\n",
    "\n",
    "@mcp.tool(name=\"handle_query\", description=\"Handle a query by recalling, reranking documents and generating an answer\")\n",
    "async def handle_query(self, query):\n",
    "    \"\"\"\n",
    "    处理查询，完成文档召回、重排与答案生成的过程\n",
    "    \"\"\"\n",
    "    # Step 1: 召回文档\n",
    "    retrieved_docs = await recall_documents(query, self.index)  # 异步召回文档\n",
    "    \n",
    "    # Step 2: 重排文档\n",
    "    reranked_docs = await rerank_documents(query, retrieved_docs)  # 异步重排文档\n",
    "    \n",
    "    # Step 3: 生成答案\n",
    "    answer = await generate_answer(query, reranked_docs)  # 异步生成答案\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# 确保 mcp.run() 运行时不与已有事件循环冲突\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    \n",
    "    # 检查是否已有事件循环在运行\n",
    "    if not asyncio.get_event_loop().is_running():\n",
    "        # 如果没有事件循环，直接调用 run()\n",
    "        mcp.run(transport='stdio')\n",
    "    else:\n",
    "        # 如果已经有事件循环运行，FastMCP 自动管理事件循环\n",
    "        print(\"Event loop is already running. FastMCP will be managed automatically.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
